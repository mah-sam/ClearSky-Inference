{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"gpuType":"T4","provenance":[]},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"07a95d46b0a844cfa7c90bbb25e295a1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_79664e929da94dfba36ff8784b4b3616","placeholder":"​","style":"IPY_MODEL_36f71ec7817a4c2298defbbdc3f35fdf","value":" 6.89k/6.89k [00:00&lt;00:00, 447kB/s]"}},"23f89c7bb0fc4e529996b38d69a2d93f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a026040b270d478cb62bdd6fd3a9b643","placeholder":"​","style":"IPY_MODEL_985b9382e0dc437fa70e4ec083919fa2","value":"(…)odels/hyperstarcop_mag1c_rgb/config.yaml: 100%"}},"2978cb436cea4ebcb168d10a0744a2d7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_625f8cbaf7de4f5f8495941e0b08085b","placeholder":"​","style":"IPY_MODEL_565ad51733dc4dbf95494c2f0650bae6","value":"final_checkpoint_model.ckpt: 100%"}},"32e9e8d4ec0d4d7ea049e1b180873b02":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36f71ec7817a4c2298defbbdc3f35fdf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3bc85bbec677429ba3660b7be97dc906":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2978cb436cea4ebcb168d10a0744a2d7","IPY_MODEL_d91951df810b45848e1eec4cfbc76c7c","IPY_MODEL_47be042a285f4f6aba9faf5b221e5bf1"],"layout":"IPY_MODEL_a3c7f9e05e144f578f8137c7a7fa44ad"}},"43c6a889579b46a3914d05674ba3cb1a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"47be042a285f4f6aba9faf5b221e5bf1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_43c6a889579b46a3914d05674ba3cb1a","placeholder":"​","style":"IPY_MODEL_4dd3d066f19c4496a9dc85b017330982","value":" 80.0M/80.0M [00:01&lt;00:00, 42.2MB/s]"}},"4dd3d066f19c4496a9dc85b017330982":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"565ad51733dc4dbf95494c2f0650bae6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"625f8cbaf7de4f5f8495941e0b08085b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a702e835cfe4b259a533d33da3cf3a5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_23f89c7bb0fc4e529996b38d69a2d93f","IPY_MODEL_7d40bcdaeed44637a4b421a779639628","IPY_MODEL_07a95d46b0a844cfa7c90bbb25e295a1"],"layout":"IPY_MODEL_32e9e8d4ec0d4d7ea049e1b180873b02"}},"6f653cfdba3a4498bb01a0abd3e0a13e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79664e929da94dfba36ff8784b4b3616":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d40bcdaeed44637a4b421a779639628":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_aea2081e4d754c499b7724bc87ba14c8","max":6891,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d21d194001f24222b1d326ec6c608537","value":6891}},"985b9382e0dc437fa70e4ec083919fa2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a026040b270d478cb62bdd6fd3a9b643":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a3c7f9e05e144f578f8137c7a7fa44ad":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aea2081e4d754c499b7724bc87ba14c8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d21d194001f24222b1d326ec6c608537":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d91951df810b45848e1eec4cfbc76c7c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6f653cfdba3a4498bb01a0abd3e0a13e","max":79998303,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f9a643f200a840e2821ed79dacf9788b","value":79998303}},"f9a643f200a840e2821ed79dacf9788b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Run STARCOP models on full granules of EMIT data\n\n>  V. Růžička, G. Mateo-Garcia, L. Gómez-Chova, A. Vaughan, L. Guanter, and A. Markham, [Semantic segmentation of methane plumes with hyperspectral machine learning models](https://www.nature.com/articles/s41598-023-44918-6). _Scientific Reports 13, 19999_ (2023). DOI: 10.1038/s41598-023-44918-6.\n\nDemo with loading the AVIRIS trained models to show zero-shot generalisation on the data from EMIT.\n\n*Update Jan 2025: the library versions were updated to work with the current Colab environment.*","metadata":{"_uuid":"edadd663-38cf-4fee-afc5-dbc25216e8e7","_cell_guid":"6f37e83c-2b47-4225-9704-f6865960c73d","trusted":true,"collapsed":false,"id":"20750ac8-a6de-45a3-9932-315ff877e5d6","jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Try this first:\n# !pip install git+https://github.com/spaceml-org/STARCOP.git\n\n# But for Google Colab (as of January 2025) instead use:\n!pip install georeader-spaceml -q\n!pip install torch==2.0.0 torchvision==0.15.1 torchtext==0.15.1 pytorch-lightning==2.2 -q\n!pip install fsspec gcsfs omegaconf kornia==0.6.7  torchmetrics==0.10.0 wandb segmentation_models_pytorch hydra-core ipython rasterio  geopandas ipykernel matplotlib scikit-image scikit-learn wandb -q\n!pip install netCDF4 spectral -q\n\n!pip install huggingface_hub[cli,torch] -q\n!pip install matplotlib-scalebar -q","metadata":{"_uuid":"e1f32be2-fe25-4162-a04f-01decd9a4519","_cell_guid":"88f7d24c-4678-4a1d-b9e7-e23e2289361c","trusted":true,"collapsed":false,"id":"e0a61303-1e27-4f32-835a-cbfa997356b1","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!git clone https://github.com/spaceml-org/STARCOP.git","metadata":{"_uuid":"4a6f9346-b9b6-4a63-b6ff-bff3b04a222f","_cell_guid":"71f3811a-4dd0-4bfb-831d-4de7f9445a24","trusted":true,"collapsed":false,"id":"Hslf7wcgqbr-","outputId":"67f363c7-f6ea-4321-ec61-d4032099024c","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%cd STARCOP","metadata":{"_uuid":"7820666f-1190-46ce-8930-f609cac25d92","_cell_guid":"8d01be15-44b1-4657-b284-c3e47747b20e","trusted":true,"collapsed":false,"id":"4XoeTFd-qen_","outputId":"de31ff84-0180-44e2-872f-863118415381","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 1: download EMIT image\n\nIn order to download and process the EMIT image we will use the emit reader in the [georeader](https://github.com/spaceml-org/georeader/) package. See [this tutorial](https://github.com/spaceml-org/georeader/blob/main/notebooks/emit_explore.ipynb) for an example of how to load and plot the data.","metadata":{"_uuid":"e8d3ff01-71db-4129-95e8-6e28bd11f496","_cell_guid":"c68afa75-80cd-4b09-b454-02ae31ebae58","trusted":true,"collapsed":false,"id":"53940bbf-1009-4413-9778-33d08156842b","jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"from huggingface_hub import hf_hub_download\nfrom georeader.readers import emit, download_utils\nfrom starcop.models import mag1c_emit\nfrom georeader import plot\nimport starcop\nfrom starcop.models.model_module import ModelModule\nimport os\nimport torch\nimport omegaconf\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom starcop.models.utils import padding\nimport georeader","metadata":{"_uuid":"ec6e4bdc-8629-49db-b6ee-0de30498374a","_cell_guid":"917d303c-7827-4997-ad05-e690113a6b1f","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"file_name = \"EMIT_L1B_RAD_001_20250813T111228_2522507_037.nc\"\ntoken = \"eyJ0eXAiOiJKV1QiLCJvcmlnaW4iOiJFYXJ0aGRhdGEgTG9naW4iLCJzaWciOiJlZGxqd3RwdWJrZXlfb3BzIiwiYWxnIjoiUlMyNTYifQ.eyJ0eXBlIjoiVXNlciIsInVpZCI6Im1haF9zYW0iLCJleHAiOjE3NjA1NzI3OTksImlhdCI6MTc1NTM1NTU0NywiaXNzIjoiaHR0cHM6Ly91cnMuZWFydGhkYXRhLm5hc2EuZ292IiwiaWRlbnRpdHlfcHJvdmlkZXIiOiJlZGxfb3BzIiwiYWNyIjoiZWRsIiwiYXNzdXJhbmNlX2xldmVsIjozfQ.459S_fTfcXafo7Yk017iH4iclfb0z41d57Rj8oTdGYRWCsGD2oGTJGYLrKKHot3JjfgS1kyc33YSAY5JmHy5I0CaYaneDriJIJrBHifka-IJBC3bGow331XgUbiAV_WOM_kJ1ReMSVz7lqr1NiMvf6YGMnE6N9QAQcGCL8UgRZNTYJx8qUrBlpYiPA3p-FQYSbYkINlRjr7myJUkiAHItQ-CTxuAuxbO0j2rdi5Hx1Aldze7NBovlBLjBNnHW6LI9XhaMvlJciXVAXw9T_AuAoD55qkP_ACRIje7hCLz_s-1srjXUGViQfFGy3ixqZuiQ6GYzXRGOU9kJPrjYUWbrA\"\nearthdata_nasa_account = True\n\n# NASA's data archive requires creating an account for downloading EMIT files directly.\n# Create an user and a token at the NASA Earthdata portal (https://urs.earthdata.nasa.gov/profile)\n\ndef download_granule(granule_name=file_name, token=token, earthdata_nasa_account=earthdata_nasa_account):\n    if earthdata_nasa_account:\n        link = emit.get_radiance_link(granule_name)\n        emit.AUTH_METHOD = \"token\"\n        emit.TOKEN = token # copy your token here\n        headers = {\"Authorization\": f\"Bearer {emit.TOKEN}\"}\n    \n        product = download_utils.download_product(link, headers=headers,  verify=True)\n    \n        rst = emit.EMITImage(product)\n    return rst\n\ngranule = download_granule()","metadata":{"_uuid":"3bc07b68-0856-48ba-8e53-854a764417cd","_cell_guid":"f1b1c692-3c7a-4ed6-8e00-f3c7048c098a","trusted":true,"collapsed":false,"id":"32e9d785-d598-4ce0-b7fa-1fca087dca91","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 3: run mag1c on the EMIT product\n\nRun mag1c filter retrieval based on the work of [Foote et al. 2020](https://ieeexplore.ieee.org/document/9034492).","metadata":{"_uuid":"5d2d48f3-8b2c-4c7c-9b2c-39201dcea8dd","_cell_guid":"2cb0c502-ccbb-45b9-8b6b-ab53678359ba","trusted":true,"collapsed":false,"id":"184c553f-7c9a-4fe8-be90-0854906adbc6","jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"def get_rgb(granule):\n    wavelengths_read = np.array([640, 550, 460])\n    bands_read = np.argmin(np.abs(wavelengths_read[:, np.newaxis] - granule.wavelengths), axis=1).tolist()\n    rst_rgb = granule.read_from_bands(bands_read)\n    rgb_raw = rst_rgb.load_raw(transpose=True)\n    return rgb_raw\n    \ndef apply_mf(granule):\n    mfoutput, albedo = mag1c_emit.mag1c_emit(granule, column_step=2, georreferenced=False)\n    return mfoutput","metadata":{"_uuid":"bbff4159-32c2-4a81-a083-f8aeac0fa682","_cell_guid":"04e25125-48c6-4a1a-ac35-ca37e5af966d","trusted":true,"collapsed":false,"id":"af620e14-d6cf-44c4-899f-19992adfee25","outputId":"e6aab3d1-e428-4ce7-81e1-a27052d6aebf","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.imshow(apply_mf(granule), vmin=0,vmax=1750)\nplt.title(\"$\\Delta$CH$_4$ [ppm x m]\")\nplt.colorbar()","metadata":{"_uuid":"2490e7f4-180c-42fe-99f7-c2453253f69b","_cell_guid":"eb9497d9-c940-45c5-a5fe-0d2ee6af3c17","trusted":true,"collapsed":false,"id":"7b6f5e22-cea8-48a8-ac9b-e5edeb2b61ee","outputId":"b54f5d82-f6b4-49a2-bfae-f5b169a36dfc","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 4: Load STARCOP model","metadata":{"_uuid":"af167d69-7d6c-4471-a408-daa98dcacd44","_cell_guid":"aa7cd0b6-d3b5-450b-8f82-baa603ed4168","trusted":true,"collapsed":false,"id":"eb4f0048-3365-4931-87b0-d1732a243c12","jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"from huggingface_hub import hf_hub_download\n# experiment_name = \"hyperstarcop_mag1c_only\"\nexperiment_name = \"hyperstarcop_mag1c_rgb\"\nsubfolder_local = f\"models/{experiment_name}\"\nconfig_file = hf_hub_download(repo_id=\"isp-uv-es/starcop\",subfolder=subfolder_local, filename=\"config.yaml\",\n                              local_dir=\".\", local_dir_use_symlinks=False)\nmodel_file = hf_hub_download(repo_id=\"isp-uv-es/starcop\",subfolder=subfolder_local,\n                             filename=\"final_checkpoint_model.ckpt\",\n                              local_dir=\".\", local_dir_use_symlinks=False)","metadata":{"_uuid":"ce807124-5540-419c-850f-9a37c6ccbcd1","_cell_guid":"2c3ae3d7-476e-4125-880c-edfcc8eada30","trusted":true,"collapsed":false,"id":"ce149939-4dfa-4d51-b358-6358fb71a6b3","outputId":"053ad011-d5e9-4092-b0d4-c0a23abd12f7","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"hsi_model_path = os.path.join(subfolder_local, \"final_checkpoint_model.ckpt\")\nhsi_config_path =  os.path.join(subfolder_local, \"config.yaml\")\n\ndevice = torch.device(\"cpu\")\nconfig_general = omegaconf.OmegaConf.load(os.path.join(os.path.dirname(os.path.abspath(starcop.__file__)), 'config.yaml'))\n\ndef load_model_with_emit(model_path, config_path):\n    config_model = omegaconf.OmegaConf.load(config_path)\n    config = omegaconf.OmegaConf.merge(config_general, config_model)\n\n    model = ModelModule.load_from_checkpoint(model_path, settings=config)\n    model.to(device)\n    model.eval() # !\n\n    print(\"Loaded model with\",model.num_channels,\"input channels\")\n\n    return model, config\n\nhsi_model, hsi_config = load_model_with_emit(hsi_model_path, hsi_config_path)\nprint(\"successfully loaded HyperSTARCOP model!\")","metadata":{"_uuid":"1bdd3c5a-9ca9-4e95-9cb7-e09d7a69903a","_cell_guid":"ea2ea851-000c-4ce9-8109-5af10eca0a5e","trusted":true,"collapsed":false,"id":"4651f598-a1ca-4ebc-86d6-c5d20890ecee","outputId":"4516f47b-54fe-4408-b44d-cfc9685b1f64","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 6: run inference","metadata":{"_uuid":"bb12b681-6f1f-469a-a434-23cb49450d08","_cell_guid":"81d5fad6-8e6a-409d-a46f-6da14910bb50","trusted":true,"collapsed":false,"id":"5379447c-9468-4ada-b4cc-e7b3d2ea9582","jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"def model_predict(granule):\n    # DIV the EMIT data by\n    MAGIC_DIV_BY = 240.\n    RGB_DIV_BY = 20.\n    # clipping too large values\n    MAGIC_CLIP_TO = [0.,2.]\n    RGB_CLIP_TO =   [0.,2.]\n    # MULT_BY to get it back to the range we saw in the AVIRIS data ...\n    MAGIC_MULT_BY = 1750.\n    RGB_MULT_BY =   60.\n    \n    \n    # NORMALISE\n    # emit rgb has max ~22\n    rgb_raw = get_rgb(granule)\n    mfoutput = apply_mf(granule)\n    e_mag1c = np.clip(mfoutput / MAGIC_DIV_BY, MAGIC_CLIP_TO[0], MAGIC_CLIP_TO[1]) * MAGIC_MULT_BY\n    e_rgb = np.clip(rgb_raw / RGB_DIV_BY, RGB_CLIP_TO[0], RGB_CLIP_TO[1]) * RGB_MULT_BY\n    input_data = np.concatenate([e_mag1c[None], e_rgb], axis=0)\n    input_data.shape\n    pred = padding.padded_predict(input_data, model=lambda x: torch.sigmoid(hsi_model(x)))\n    return pred\n\npred = model_predict(granule)","metadata":{"_uuid":"876b833e-2501-41da-a5d4-288078c58552","_cell_guid":"2107a50e-4798-4d66-80da-992e4f8b23aa","trusted":true,"collapsed":false,"id":"c57cca88-1658-449d-bd51-97b6a95fd1ba","outputId":"24dfecbd-9005-413f-ff84-c8dd0e315603","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.imshow(pred[0],vmin=0,vmax=1)","metadata":{"_uuid":"420b2021-2e68-47f8-8f84-6fe8cf560bb2","_cell_guid":"a73282ca-c062-46cd-b970-b70b1d316439","trusted":true,"collapsed":false,"id":"e4eb9dc0-e4f6-4dbf-a027-d6dac3b2ad34","outputId":"a32c1be3-4581-4854-8c81-1d34962909e7","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"crs_utm = georeader.get_utm_epsg(granule.footprint(\"EPSG:4326\"))\nemit_image_utm = granule.to_crs(crs_utm)\nmfgeo = emit_image_utm.georreference(apply_mf(granule), fill_value_default=-1)\npredgeo = emit_image_utm.georreference(pred[0], fill_value_default=0)\nrgbgeo = emit_image_utm.georreference(get_rgb(granule), fill_value_default=-1)\ntransform = predgeo.transform\n#utm_x, utm_y = transform * (max_col + 0.5, max_row + 0.5)\nsource_crs = predgeo.crs","metadata":{"_uuid":"fd8c2816-0400-4628-8794-fb9c5ea9edd5","_cell_guid":"46d1233d-8a4a-4b5a-b9b7-906f41b4e92f","trusted":true,"collapsed":false,"id":"f81ad922-8d6c-4157-bfd4-5b69a207a0a7","jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom skimage import measure\nfrom scipy.spatial.distance import cdist # Efficiently calculate distances\nfrom pyproj import Transformer\n\ndef get_maxima(pred, threshold=0.5, min_distance=40, border_margin=0):\n    # --- Assume 'pred_map' is your 2D prediction array ---\n    pred_map = pred.squeeze() \n    ## Step 7: georreference and plot results\n    image_height, image_width = pred_map.shape\n    \n    # --- Step 1 & 2: Threshold, Label, and Find Initial Maxima ---\n    binary_mask = pred_map > threshold\n    labeled_mask, num_labels = measure.label(binary_mask, connectivity=2, return_num=True)\n    \n    initial_maxima = []\n    for i in range(1, num_labels + 1):\n        component_mask = (labeled_mask == i)\n        component_values = np.where(component_mask, pred_map, 0)\n        \n        # Find the coordinate and value of the max in this component\n        max_coord = np.unravel_index(np.argmax(component_values), pred_map.shape)\n        max_value = component_values[max_coord]\n        \n        # Store as a dictionary for easy sorting and access\n        initial_maxima.append({'coord': max_coord, 'value': max_value})\n    \n    print(f\"Found {len(initial_maxima)} initial blobs.\")\n    \n    # --- Step 3: Filter by Edge ---\n    edge_filtered_maxima = []\n    for maxima in initial_maxima:\n        row, col = maxima['coord']\n        if (border_margin <= row < image_height - border_margin and\n            border_margin <= col < image_width - border_margin):\n            edge_filtered_maxima.append(maxima)\n        else:\n            print(f\"  - Discarding maxima at ({row}, {col}) due to border proximity.\")\n    \n    print(f\"{len(edge_filtered_maxima)} maxima remaining after edge filtering.\")\n    \n    # --- Step 4: Filter by Proximity (Greedy Suppression) ---\n    # Sort the maxima by value in descending order (highest first)\n    sorted_maxima = sorted(edge_filtered_maxima, key=lambda m: m['value'], reverse=True)\n\n    final_maxima_coords = []\n    while sorted_maxima:\n        # Pop the highest value maximum from the list\n        current_max = sorted_maxima.pop(0)\n        final_maxima_coords.append(current_max['coord'])\n        \n        # If there are no other maxima left, we're done\n        if not sorted_maxima:\n            break\n            \n        # Get coordinates for comparison\n        current_coord = np.array([current_max['coord']])\n        remaining_coords = np.array([m['coord'] for m in sorted_maxima])\n        \n        # Calculate distances between the current max and all others\n        distances = cdist(current_coord, remaining_coords)[0]\n        \n        # Keep only those maxima that are further away than min_distance\n        # We build a new list of the survivors\n        survivors = []\n        for i, is_far_enough in enumerate(distances >= min_distance):\n            if is_far_enough:\n                survivors.append(sorted_maxima[i])\n                \n        sorted_maxima = survivors # Replace the list with the filtered survivors\n    \n    print(f\"{len(final_maxima_coords)} maxima remaining after proximity filtering.\")\n\n    # --- Create a blank mask with the same shape as the original prediction map ---\n    maxima_mask = np.zeros_like(pred[0], dtype=np.uint8)\n    \n    # --- Mark the locations of your final maxima on this mask ---\n    if final_maxima_coords:\n        for row, col in final_maxima_coords:\n            maxima_mask[row, col] = 1 # Set the pixel value to 1 at each maximum\n    \n    # --- Apply the EXACT SAME georeferencing transformation ---\n    # This ensures the points are in the same coordinate system as your images.\n    maxima_geo = emit_image_utm.georreference(maxima_mask, fill_value_default=0)\n    \n    print(\"Successfully created a georeferenced layer for the maxima points.\")\n    \n    # Lists to store the final, correctly transformed coordinates\n    plot_utm_x = []\n    plot_utm_y = []\n    final_geo_coordinates = []\n    \n    # Prepare the coordinate transformer\n    source_crs = maxima_geo.crs\n    target_crs = \"EPSG:4326\"\n    transformer = Transformer.from_crs(source_crs, target_crs, always_xy=True)\n    \n    # Find the locations of our markers within the georeferenced object\n    # np.where will give us the (row, col) indices of all non-zero pixels\n    marker_rows, marker_cols = np.where(maxima_geo.values == 1)\n    \n    if len(marker_rows) > 0:\n        # Convert these pixel indices to UTM coordinates using the object's transform\n        plot_utm_x, plot_utm_y = maxima_geo.transform * (marker_cols + 0.5, marker_rows + 0.5)\n    \n        # Now, convert these correct UTM coordinates to Lat/Lon for the links\n        for x, y in zip(plot_utm_x, plot_utm_y):\n            lon, lat = transformer.transform(x, y)\n            final_geo_coordinates.append({'lat': lat, 'lon': lon})\n    else:\n        print(\"No maxima to process.\")\n    return final_maxima_coords, final_geo_coordinates\n\nfinal_maxima_coords, final_geo_coordinates = get_maxima(pred)\n# --- Step 5: Visualize the Final Results ---\nplt.figure(figsize=(14, 12))\nplt.imshow(pred.squeeze(), cmap='inferno', vmin=0, vmax=1)\nplt.colorbar(label='Prediction Confidence')\nplt.title(f'Final {len(final_maxima_coords)} Maxima')\n\n# Plot only the final, filtered maxima\nif final_maxima_coords:\n    final_cols, final_rows = zip(*[(col, row) for row, col in final_maxima_coords])\n    plt.plot(final_cols, final_rows, 'c+', markersize=15, markeredgewidth=3, linestyle='None', label='Final Maxima')\n\nplt.legend()\nplt.show()","metadata":{"_uuid":"483d309d-107b-4756-a03e-2399ce242b73","_cell_guid":"e1e2fc53-99f2-498e-9d50-4ee9ef029646","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Step 7: georreference and plot results","metadata":{"_uuid":"ae7ad7f2-f0e7-4855-8070-7b9f04b89334","_cell_guid":"777f3e86-2da4-4f2a-b9c8-dfadedc86edc","trusted":true,"collapsed":false,"id":"06b8c503-b887-40b7-91a0-c21e4320fe89","jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# from pyproj import Transformer\n# # Prepare the tools for conversion (do this once for efficiency)\n# affine_transform = predgeo.transform\n# source_crs = predgeo.crs\n# target_crs = \"EPSG:4326\" # WGS84 for Lat/Lon\n# transformer = Transformer.from_crs(source_crs, target_crs, always_xy=True)\n\n# final_geo_coordinates = [] # A list to store the final lat/lon pairs\n\n# if not final_maxima_coords:\n#     print(\"No maxima found after filtering.\")\n# else:\n#     for i, (row, col) in enumerate(final_maxima_coords):\n#         # A) Convert pixel to UTM\n#         utm_x, utm_y = affine_transform * (col + 0.5, row + 0.5)\n        \n#         # B) Convert UTM to Lat/Lon\n#         lon, lat = transformer.transform(utm_x, utm_y)\n        \n#         # Store the result\n#         final_geo_coordinates.append({'lat': lat, 'lon': lon})\n\n# # --- Step 6: Visualize the Final Results ---\n# plt.figure(figsize=(14, 12))\n# plt.imshow(pred_map, cmap='inferno', vmin=0, vmax=1)\n# plt.colorbar(label='Prediction Confidence')\n# plt.title(f'Final {len(final_maxima_coords)} Maxima (min_dist={min_distance}, border={border_margin})')\n\n# if final_maxima_coords:\n#     final_cols, final_rows = zip(*[(col, row) for row, col in final_maxima_coords])\n#     plt.plot(final_cols, final_rows, 'c+', markersize=15, markeredgewidth=3, linestyle='None', label='Final Maxima')\n#     plt.legend()\n\n# plt.show()","metadata":{"_uuid":"d7f722db-41d4-4deb-8fd4-ca760641ea36","_cell_guid":"93fd8c54-e16f-49b4-ad58-165e2e049543","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Your final plotting block, now with text annotations only on the first map ---\nfig, ax = plt.subplots(1, 3, figsize=(18, 6), sharex=True, sharey=True)\n\n# --- Plot 1: RGB Image ---\nrgbgeomask = np.any(rgbgeo.values == -1, axis=0, keepdims=False)\nrgbplot = (rgbgeo/12).clip(0,1)\nrgbplot.values[:, rgbgeomask] = -1\nplot.show(rgbplot, ax=ax[0], title=\"RGB\", mask=True, add_scalebar=True)\n\n# --- Plot 2: Methane Enhancement Map ---\nplot.show(mfgeo, ax=ax[1], title=\"$\\Delta$CH$_4$ [ppm x m]\", mask=True, vmin=0, vmax=1750,\n         add_colorbar_next_to=True, add_scalebar=True)\n\n# --- Plot 3: Prediction Map ---\nplot.show(predgeo, ax=ax[2], title=\"Prediction\", mask=True, vmin=0, vmax=1, add_scalebar=True,\n          add_colorbar_next_to=True)\n\nplt.tight_layout()\nplt.show()\n\n\n# --- Step 4: Print the Final, Correct Google Maps Links ---\nprint(\"\\n\" + \"=\"*50)\nprint(\"GEOGRAPHIC LOCATIONS OF FINAL MAXIMA\")\nprint(\"=\"*50)\n\nif not final_geo_coordinates:\n    print(\"No maxima found after filtering.\")\nelse:\n    print\n    for i, coords in enumerate(final_geo_coordinates):\n        print(f\"\\n--- Maximum #{i + 1} ---\")\n        print(f\"Latitude:  {coords['lat']:.6f}\")\n        print(f\"Longitude: {coords['lon']:.6f}\")\n        print(f\"Google Maps Link: https://www.google.com/maps?q={coords['lat']},{coords['lon']}\")","metadata":{"_uuid":"d42e3cd1-1032-43f1-92b0-e9dd7ddb66f4","_cell_guid":"7d54ef86-ba58-44c4-a6a1-c865800c6c9f","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import folium\nfrom folium.plugins import HeatMap\nimport numpy as np\nfrom pyproj import Transformer\nimport branca # Folium's parent library\nfrom jinja2 import Template # Used to create the custom element's template\n\n# ==============================================================================\n# This script generates a map where clicking anywhere creates a popup with a\n# link to Google Maps.\n#\n# REQUIRED INPUT VARIABLES:\n# - predgeo: The georeferenced GeoTensor of the prediction heatmap.\n# - final_geo_coordinates: A list of {'lat': ..., 'lon': ...} dicts for each detected source.\n#\n# ==============================================================================\n\n# --- Step 1 & 2: Prepare Data and Transform Coordinates (Same as before) ---\ndef visualize_output(predgeo, final_geo_coordinates=None, heatmap_threshold=0.4):\n    prediction_pixels = predgeo.values\n    rows, cols = np.where(prediction_pixels >= heatmap_threshold)\n    scores = prediction_pixels[rows, cols].astype(float)\n    affine_transform = predgeo.transform\n    source_crs = predgeo.crs\n    target_crs = \"EPSG:4326\"\n    transformer = Transformer.from_crs(source_crs, target_crs, always_xy=True)\n    utm_x, utm_y = affine_transform * (cols + 0.5, rows + 0.5)\n    lons, lats = transformer.transform(utm_x, utm_y)\n    heatmap_data = list(zip(lats, lons, scores))\n    \n    # --- Step 3: Define Map Center and Create the Base Map (Same as before) ---\n    if final_geo_coordinates:\n        map_center = [final_geo_coordinates[0]['lat'], final_geo_coordinates[0]['lon']]\n        points_layer = folium.FeatureGroup(name='Detected Plume Sources', show=True)\n        for i, coords in enumerate(final_geo_coordinates):\n            lat, lon = coords['lat'], coords['lon']\n            popup_html = f\"<b>Candidate #{i+1}</b><br>Lat: {lat:.6f}, Lon: {lon:.6f}<br><a href='https://www.google.com/maps?q={lat},{lon}' target='_blank'>Google Maps</a>\"\n            folium.Marker(\n                location=[lat, lon],\n                popup=folium.Popup(popup_html, max_width=300),\n                icon=folium.Icon(color='cyan', icon='cloud', prefix='fa')\n            ).add_to(points_layer)\n    else:\n        footprint_wgs84 = predgeo.footprint(\"EPSG:4326\")\n        min_lon, min_lat, max_lon, max_lat = footprint_wgs84.bounds\n        map_center = [(min_lat + max_lat) / 2, (min_lon + max_lon) / 2]\n    m_final = folium.Map(location=map_center, zoom_start=14, tiles=\"Esri.WorldImagery\")\n    \n    # --- Step 4: Create and Populate All Layers (Same as before) ---\n    heatmap_layer = folium.plugins.HeatMap(data=heatmap_data, name='Dynamic Methane Heatmap')\n    \n    # --- Step 5: Add \"Click for Popup\" Functionality (THE MODIFIED VERSION) ---\n    \n    # We modify our custom class to create a Leaflet popup instead of opening a new window.\n    class ClickForPopup(branca.element.MacroElement):\n        _template = Template(u\"\"\"\n            {% macro script(this, kwargs) %}\n                function create_popup_on_click(e) {\n                    var lat = e.latlng.lat;\n                    var lon = e.latlng.lng;\n                    var url = `https://www.google.com/maps?q=${lat},${lon}`;\n                    \n                    // Create the HTML content for the popup\n                    var html = `\n                        <b>Location Info</b><br>\n                        Latitude: ${lat.toFixed(6)}<br>\n                        Longitude: ${lon.toFixed(6)}\n                        <hr style=\"margin: 5px 0;\">\n                        <ul>\n                            <li><a href=\"${url}\" target=\"_blank\" rel=\"noopener noreferrer\">View in Google Maps</a></li>\n                        </ul>\n                    `;\n                    \n                    // Create a Leaflet popup object and open it on the map\n                    var popup = L.popup()\n                        .setLatLng(e.latlng)\n                        .setContent(html)\n                        .openOn({{this._parent.get_name()}});\n                }\n                // Attach the function to the map's click event\n                {{this._parent.get_name()}}.on('click', create_popup_on_click);\n            {% endmacro %}\n            \"\"\")\n    \n        def __init__(self):\n            super(ClickForPopup, self).__init__()\n            self._name = 'ClickForPopup'\n    \n    # Create an instance of our custom element and add it to the map.\n    m_final.add_child(ClickForPopup())\n    \n    \n    # --- Step 6: Add Layers to the Map and Save ---\n    heatmap_layer.add_to(m_final)\n    if final_geo_coordinates:\n        points_layer.add_to(m_final)\n    folium.LayerControl().add_to(m_final)\n    output_map_path_final = 'methane_detection_map_popup.html'\n    m_final.save(output_map_path_final)\n    print(f\"Interactive map with popups saved to: {output_map_path_final}\")\n    return m_final\n\n#m_final = visualize_output(predgeo, final_geo_coordinates)\n#m_final","metadata":{"_uuid":"890b154d-4019-415f-b192-82c0d79e75fb","_cell_guid":"ca346b53-e3e4-4e5e-ad3e-bc5b29d51889","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 8. Detection Over Multiple Granules","metadata":{"_uuid":"3d72afa2-3333-40aa-9429-a6ee03de9cb1","_cell_guid":"e3ecd04b-2a15-42cd-a241-9396dc4a0efc","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"granule_names = [\"EMIT_L1B_RAD_001_20250730T075636_2521105_018.nc\",\\\n                \"EMIT_L1B_RAD_001_20250813T111228_2522507_037.nc\",\\\n                \"EMIT_L1B_RAD_001_20250417T095633_2510706_024.nc\",\\\n                \"EMIT_L1B_RAD_001_20250413T113146_2510307_040.nc\",\\\n                \"EMIT_L1B_RAD_001_20241007T051258_2428104_006.nc\",\\\n                \"EMIT_L1B_RAD_001_20241003T064746_2427705_017.nc\"]\ngranules = {}","metadata":{"_uuid":"bb50d324-4c04-4c27-80a5-957fe79a4b17","_cell_guid":"11966b5f-7a01-444a-ba3d-75ce4fbac9a6","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for granule_name in granule_names:\n    granule = download_granule(granule_name)\n    pred = model_predict(granule)\n    crs_utm = georeader.get_utm_epsg(granule.footprint(\"EPSG:4326\"))\n    emit_image_utm = granule.to_crs(crs_utm)\n    predgeo = emit_image_utm.georreference(pred[0], fill_value_default=0)\n    final_maxima_coords, final_geo_coordinates = get_maxima(pred)\n    visualization = visualize_output(predgeo, final_geo_coordinates)\n    granules[granule_name] = {\"granule\":granule, \"pred\":pred, \"predgeo\":predgeo, \"maxima\":final_maxima_coords, \"geomaxima\":final_geo_coordinates, \"visualization\":visualization}","metadata":{"_uuid":"13006bad-e671-4a81-ae41-5ff06ce455fd","_cell_guid":"8a989af5-dc63-44f7-ab9f-071eb589d97d","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"granules[granule_names[0]][\"visualization\"]","metadata":{"_uuid":"f9c578ec-c1da-4a74-80bf-538481cacdfd","_cell_guid":"ad5311a0-906e-4514-9e99-c7adbcec84c7","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for name, g in granules.items():\n    export_to_geotiff_compressed(\n        g[\"predgeo\"],\n        f\"starcop_output_{name}.tif\",\n        compression='DEFLATE'\n    )","metadata":{"_uuid":"55945aa1-9abe-498a-a032-18a99ed815be","_cell_guid":"87a8946d-2a81-4e51-8e12-4b34836cd424","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ls","metadata":{"_uuid":"9fcb8e2f-707a-4705-928b-2c340ede41b6","_cell_guid":"985330e6-a9ad-47b7-b835-12ee509c2e4a","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 9. Aggregating Timeline","metadata":{"_uuid":"fff35265-6ed3-48b6-9d32-39376d23929e","_cell_guid":"69081517-82b4-4b9d-bf05-b5c04c8cf535","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"!pip install rasterio -q","metadata":{"_uuid":"8fc9e717-6fea-4b63-b9b8-559de2baad39","_cell_guid":"706faeea-5faa-4d13-8fe7-bde484001a16","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport rasterio\nfrom rasterio.crs import CRS\nfrom rasterio.warp import calculate_default_transform, reproject, Resampling\nfrom shapely.geometry import box\n\ndef aggregate_rasters_on_union(predgeo_objects):\n    \"\"\"\n    Takes a list of misaligned georeferenced raster objects, aligns them to their\n    total combined extent (union), and returns two new objects:\n    1. The normalized mean signal map (0 to 1).\n    2. The observation count map (confidence).\n\n    Args:\n        predgeo_objects (list): A list of your georeferenced raster objects.\n\n    Returns:\n        tuple: A tuple containing two new georeferenced objects:\n            - (mean_signal_geo, observation_count_geo)\n    \"\"\"\n    if not predgeo_objects:\n        return None, None\n\n    # --- Step 1: Establish Common Grid based on UNION ---\n    print(\"Step 1: Establishing a common grid based on UNION...\")\n    target_crs = CRS.from_user_input(predgeo_objects[0].crs)\n    \n    b = predgeo_objects[0].footprint(target_crs).bounds\n    total_left, total_bottom, total_right, total_top = b[0], b[1], b[2], b[3]\n    for pg in predgeo_objects[1:]:\n        b = pg.footprint(target_crs).bounds\n        total_left = min(total_left, b[0])\n        total_bottom = min(total_bottom, b[1])\n        total_right = max(total_right, b[2])\n        total_top = max(total_top, b[3])\n        \n    target_res = (abs(predgeo_objects[0].transform.a), abs(predgeo_objects[0].transform.e))\n    common_transform, common_width, common_height = calculate_default_transform(\n        target_crs, target_crs, \n        width=int((total_right - total_left) / target_res[0]), \n        height=int((total_top - total_bottom) / target_res[1]),\n        left=total_left, bottom=total_bottom, right=total_right, top=total_top\n    )\n\n    # --- Step 2 & 3: Reproject and Aggregate ---\n    print(\"\\nStep 2 & 3: Reprojecting granules and aggregating...\")\n    sum_raster = np.zeros((common_height, common_width), dtype=np.float32)\n    count_raster = np.zeros((common_height, common_width), dtype=np.int16)\n    \n    for i, pg in enumerate(predgeo_objects):\n        print(f\"  - Processing granule {i+1}/{len(predgeo_objects)}...\")\n        reprojected_granule = np.zeros((common_height, common_width), dtype=np.float32)\n        reproject(\n            source=pg.values, destination=reprojected_granule,\n            src_transform=pg.transform, src_crs=CRS.from_user_input(pg.crs),\n            dst_transform=common_transform, dst_crs=target_crs,\n            resampling=Resampling.average, dst_nodata=0\n        )\n        sum_raster += reprojected_granule\n        count_raster[reprojected_granule > 0] += 1\n\n    # --- Step 4: Calculate the Mean Signal Map ---\n    print(\"\\nStep 4: Calculating the mean signal map...\")\n    # Nodata value for areas with no coverage\n    nodata_value = -1 \n    mean_signal_raster = np.divide(\n        sum_raster, count_raster, \n        out=np.full_like(sum_raster, fill_value=nodata_value),\n        where=count_raster != 0\n    )\n    \n    # --- Step 5: Normalize the Mean Signal Map to [0, 1] ---\n    print(\"Step 5: Normalizing the mean signal map...\")\n    # Create a mask to ignore nodata values during normalization\n    valid_mask = mean_signal_raster != nodata_value\n    \n    if np.any(valid_mask):\n        min_val = np.min(mean_signal_raster[valid_mask])\n        max_val = np.max(mean_signal_raster[valid_mask])\n        \n        if max_val > min_val:\n            # Apply min-max normalization only to the valid data\n            normalized_raster = np.full_like(mean_signal_raster, fill_value=nodata_value)\n            normalized_raster[valid_mask] = (mean_signal_raster[valid_mask] - min_val) / (max_val - min_val)\n        else:\n            # Handle case where all values are the same\n            normalized_raster = np.full_like(mean_signal_raster, fill_value=0.5)\n            normalized_raster[~valid_mask] = nodata_value # Restore nodata\n    else:\n        # Handle case where there is no valid data at all\n        normalized_raster = mean_signal_raster\n\n    # --- Step 6: Construct and Return the Final Objects ---\n    print(\"Step 6: Constructing the final georeferenced objects...\")\n    GeoObjectType = type(predgeo_objects[0])\n    \n    mean_signal_geo = GeoObjectType(\n        values=normalized_raster, \n        transform=common_transform, \n        crs=target_crs.to_string()\n    )\n    \n    observation_count_geo = GeoObjectType(\n        values=count_raster,\n        transform=common_transform,\n        crs=target_crs.to_string()\n    )\n    \n    print(\"Aggregation complete. Returning mean signal and observation count objects.\")\n    return mean_signal_geo, observation_count_geo\n\nimport numpy as np\n\ndef calculate_final_confidence(mean_signal_geo, count_geo):\n    \"\"\"\n    Combines a normalized mean signal map and an observation count map into a\n    final confidence score, which is then re-normalized to span the full [0, 1] range.\n\n    Args:\n        mean_signal_geo (GeoTensor): The object for the normalized mean signal.\n        count_geo (GeoTensor): The object for the observation count.\n\n    Returns:\n        tuple: A tuple containing two georeferenced objects:\n            - final_confidence_geo: The final, re-normalized confidence score map.\n            - penalized_score_geo: The intermediate, non-normalized penalized score map (for comparison).\n    \"\"\"\n    mean_signal = mean_signal_geo.values\n    count_map = count_geo.values.astype(np.float32)\n    nodata_value = -1\n\n    # --- Step 1: Create a Count Weight Map [0, 1] ---\n    valid_mask = count_map > 0\n    count_weight_map = np.full_like(count_map, fill_value=0.0)\n    if np.any(valid_mask):\n        max_count = np.max(count_map[valid_mask])\n        if max_count > 0:\n            count_weight_map[valid_mask] = count_map[valid_mask] / max_count\n\n    # --- Step 2: Calculate the Intermediate Penalized Score ---\n    signal_valid_mask = mean_signal != nodata_value\n    penalized_score_map = np.full_like(mean_signal, fill_value=nodata_value)\n    penalized_score_map[signal_valid_mask] = mean_signal[signal_valid_mask] * count_weight_map[signal_valid_mask]\n\n    # --- Step 3: Re-Normalize the Penalized Score Map ---\n    final_normalized_map = np.full_like(penalized_score_map, fill_value=nodata_value)\n    final_valid_mask = penalized_score_map != nodata_value\n\n    if np.any(final_valid_mask):\n        min_score = np.min(penalized_score_map[final_valid_mask])\n        max_score = np.max(penalized_score_map[final_valid_mask])\n        \n        if max_score > min_score:\n            # Stretch the penalized scores to the full [0, 1] range\n            final_normalized_map[final_valid_mask] = (penalized_score_map[final_valid_mask] - min_score) / (max_score - min_score)\n        else:\n            # Handle case where all valid scores are the same after penalization\n            final_normalized_map[final_valid_mask] = 0.5\n    \n    # --- Step 4: Construct and Return the Final Georeferenced Objects ---\n    GeoObjectType = type(mean_signal_geo)\n    \n    # Create an object for the final, normalized result\n    final_confidence_geo = GeoObjectType(\n        values=final_normalized_map,\n        transform=mean_signal_geo.transform,\n        crs=mean_signal_geo.crs\n    )\n    \n    # Also create an object for the intermediate step for clear comparison\n    penalized_score_geo = GeoObjectType(\n        values=penalized_score_map,\n        transform=mean_signal_geo.transform,\n        crs=mean_signal_geo.crs\n    )\n\n    return final_confidence_geo\n\n# --- Example Usage ---\npredgeo_list = [data[\"predgeo\"] for data in granules.values()]\nmean_pred_geo, count_geo = aggregate_rasters_on_union(predgeo_list)\n\nif mean_pred_geo and count_geo:\n    print(\"\\nSuccessfully created the aggregated objects.\")\n    # You can now visualize BOTH `mean_pred_geo` and `count_geo` on separate maps\n    # or side-by-side to get the full picture.\n\nfinal_confidence_score_geo = calculate_final_confidence(mean_pred_geo, count_geo)\n\n# Now you have a single, powerful map to visualize!\nif final_confidence_score_geo:\n    print(\"Successfully created the final confidence score map.\")\n    # You can now pass `final_confidence_score_geo` to your Folium visualization.\n\nfinal_confidence_score_geo = calculate_final_confidence(mean_pred_geo, count_geo)\n\nif final_confidence_score_geo:\n    print(\"Successfully created the final, re-normalized confidence score map.\")\n    # The `values` of this object are now guaranteed to be between 0 and 1 (and -1 for nodata).\n    # It's ready for perfect visualization.","metadata":{"_uuid":"5c574e35-f961-48ce-8fa3-10b383657c4e","_cell_guid":"799fe9f6-19b4-471f-9a90-5a6f0f7c1737","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import rasterio\n\ndef export_to_geotiff_compressed(geopred_object, output_filepath, compression='DEFLATE'):\n    \"\"\"\n    Exports a georeferenced raster object to a COMPRESSED GeoTIFF file.\n\n    Args:\n        geopred_object (GeoTensor): The object to export.\n        output_filepath (str): The path to save the new .tif file.\n        compression (str): The compression method to use.\n                           Recommended: 'DEFLATE', 'LZW'.\n                           For visualization only: 'JPEG', 'WEBP'.\n    \"\"\"\n    raster_data = geopred_object.values\n    transform = geopred_object.transform\n    crs = geopred_object.crs\n    nodata_value = -1\n\n    metadata = {\n        'driver': 'GTiff',\n        'height': raster_data.shape[0],\n        'width': raster_data.shape[1],\n        'count': 1,\n        'dtype': raster_data.dtype,\n        'crs': crs,\n        'transform': transform,\n        'nodata': nodata_value,\n        'compress': compression  # <-- THE KEY ADDITION\n    }\n    \n    # For some compression types, you can add extra options\n    # For example, for JPEG:\n    # with rasterio.open(..., compress='JPEG', jpeg_quality=85) as dst:\n\n    with rasterio.open(output_filepath, 'w', **metadata) as dst:\n        dst.write(raster_data, 1)\n        \n    print(f\"Raster data successfully exported to {output_filepath} with {compression} compression.\")\n\n# --- Example Usage ---\n# Export with the recommended lossless compression\nexport_to_geotiff_compressed(\n    final_confidence_score_geo,\n    \"final_methane_confidence_map_compressed.tif\",\n    compression='DEFLATE'\n)","metadata":{"_uuid":"5f772b63-8957-4251-b0cc-76cb9c966a14","_cell_guid":"40f6fbf1-b18f-49a0-86fc-c01bfb4456be","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\n\ndef compare_signal_and_confidence(mean_signal_geo, count_geo, final_confidence_score_geo):\n    \"\"\"\n    Compares average AND maximum pixel values before and after applying the confidence score.\n    Provides both a global summary and a detailed breakdown by observation count.\n\n    Args:\n        mean_signal_geo (GeoTensor): The georeferenced object for the normalized mean signal.\n        count_geo (GeoTensor): The georeferenced object for the observation count.\n        final_confidence_score_geo (GeoTensor): The georeferenced object for the final score.\n    \"\"\"\n    # Extract the NumPy arrays from the georeferenced objects\n    mean_signal = mean_signal_geo.values\n    count_map = count_geo.values\n    final_confidence = final_confidence_score_geo.values\n    \n    # Define the nodata value used in your rasters\n    nodata_value = -1\n\n    print(\"=\"*60)\n    print(\"Comparison of Mean Signal vs. Final Confidence Score\")\n    print(\"=\"*60)\n\n    # --- 1. Global Summary Comparison (Average and Max) ---\n    print(\"\\n--- Global Summary (across all pixels with data) ---\")\n\n    # Create a mask for all valid pixels\n    valid_mask = count_map > 0\n\n    if not np.any(valid_mask):\n        print(\"No valid data found in the maps to compare.\")\n        return\n\n    # Calculate global averages\n    avg_before = np.mean(mean_signal[valid_mask])\n    avg_after = np.mean(final_confidence[valid_mask])\n    \n    # --- NEW: Calculate global maximums ---\n    max_before = np.max(mean_signal[valid_mask])\n    max_after = np.max(final_confidence[valid_mask])\n    \n    print(f\"Average Signal (Before Scoring):   {avg_before:.4f}\")\n    print(f\"Average Confidence (After Scoring):  {avg_after:.4f}\")\n    print(\"-\" * 40)\n    print(f\"Maximum Signal (Before Scoring):   {max_before:.4f}\")\n    print(f\"Maximum Confidence (After Scoring):  {max_after:.4f}\")\n    \n    # --- 2. Breakdown by Observation Count ---\n    print(\"\\n--- Breakdown by Observation Count ---\")\n\n    unique_counts = np.unique(count_map[valid_mask])\n\n    for count in unique_counts:\n        # Create a specific mask for pixels with this exact observation count\n        count_mask = count_map == count\n        num_pixels = np.sum(count_mask)\n\n        # Calculate averages for this subset\n        avg_before_subset = np.mean(mean_signal[count_mask])\n        avg_after_subset = np.mean(final_confidence[count_mask])\n        \n        # --- NEW: Calculate maximums for this subset ---\n        max_before_subset = np.max(mean_signal[count_mask])\n        max_after_subset = np.max(final_confidence[count_mask])\n        \n        print(f\"\\nFor {num_pixels} pixels seen {int(count)} time(s):\")\n        print(f\"  - Avg Signal Before: {avg_before_subset:.4f}  |  Max Signal Before: {max_before_subset:.4f}\")\n        print(f\"  - Avg Signal After:  {avg_after_subset:.4f}  |  Max Signal After:  {max_after_subset:.4f}\")\n\n    print(\"\\n\" + \"=\"*60)\n    print(\"Analysis complete.\")\n\n\n# --- Example Usage ---\n# Assume `mean_pred_geo`, `count_geo`, and `final_confidence_score_geo`\n# are the outputs from your previous, corrected functions.\n\ncompare_signal_and_confidence(mean_pred_geo, count_geo, final_confidence_score_geo)\n\n\n# --- Example Usage ---\n# Assume `mean_pred_geo`, `count_geo`, and `final_confidence_score_geo`\n# are the outputs from your previous functions.\n\n# Just call the function with your three objects.\ncompare_signal_and_confidence(mean_pred_geo, count_geo, final_confidence_score_geo)","metadata":{"_uuid":"bca43d0b-9931-49c2-84b3-90615c73d440","_cell_guid":"f3957e0b-cf85-48bd-b86d-99a94137fa89","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"visualize_output(final_confidence_score_geo, heatmap_threshold=0.6)","metadata":{"_uuid":"b5d693db-2326-443b-8ec9-bf48415d0aaa","_cell_guid":"d4a4a09a-3f82-488c-af18-0c5b8b418c80","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Run Project-Eucalyptus","metadata":{"_uuid":"9a5c5f01-b4a4-463c-b319-7413612680d0","_cell_guid":"52dd9675-94b2-4c5f-bda8-1d94a36bd758","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"## Loading Model","metadata":{"_uuid":"4eb2ab60-920b-44c4-97ff-60536264f142","_cell_guid":"c1e01df6-4cb0-42b1-a3de-cc3fd842575c","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"!git clone https://github.com/Orbio-Earth/Project-Eucalyptus.git","metadata":{"_uuid":"5a4d33bf-cd79-4b32-8b45-ed0cbfaa52fb","_cell_guid":"0925f314-b1bb-4246-832b-c15ecbbb7187","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-09-09T08:36:17.705873Z","iopub.execute_input":"2025-09-09T08:36:17.706338Z","iopub.status.idle":"2025-09-09T08:36:17.863388Z","shell.execute_reply.started":"2025-09-09T08:36:17.706308Z","shell.execute_reply":"2025-09-09T08:36:17.862028Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"fatal: destination path 'Project-Eucalyptus' already exists and is not an empty directory.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"%cd Project-Eucalyptus/notebooks","metadata":{"_uuid":"83d54a90-0d2f-4be5-a52f-6cb13df7ac25","_cell_guid":"2463390e-f7ef-4fb8-9fe4-448baf55abf9","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-09-09T08:36:17.865543Z","iopub.execute_input":"2025-09-09T08:36:17.866213Z","iopub.status.idle":"2025-09-09T08:36:17.875838Z","shell.execute_reply.started":"2025-09-09T08:36:17.866177Z","shell.execute_reply":"2025-09-09T08:36:17.874712Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"/kaggle/working/Project-Eucalyptus/notebooks\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Choose ONE of the following commands based on how you uploaded the file.\n\n# If you used Option A (Added as a Dataset):\n# !pip install -r /kaggle/input/my-project-reqs/requirements.txt --upgrade --no-cache-dir\n\n# If you used Option B (Uploaded directly):\n!pip install -r ../requirements.txt --upgrade --no-cache-dir -q","metadata":{"_uuid":"3fac00fa-b7d3-4166-9e33-5fb15b523577","_cell_guid":"98378e01-ba49-419c-ba31-27c436c1033e","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-09-09T08:36:17.877259Z","iopub.execute_input":"2025-09-09T08:36:17.877540Z","iopub.status.idle":"2025-09-09T08:40:21.073632Z","shell.execute_reply.started":"2025-09-09T08:36:17.877521Z","shell.execute_reply":"2025-09-09T08:40:21.071712Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m125.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m251.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m293.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m70.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m327.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m217.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.7/431.7 kB\u001b[0m \u001b[31m234.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m190.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.5/21.5 MB\u001b[0m \u001b[31m132.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.8/14.8 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.3/121.3 kB\u001b[0m \u001b[31m217.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m159.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.2/821.2 MB\u001b[0m \u001b[31m206.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m301.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m249.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m93.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m181.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m329.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m198.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m159.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m351.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m208.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m265.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m233.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m206.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m234.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 kB\u001b[0m \u001b[31m290.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m313.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m138.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.4/35.4 MB\u001b[0m \u001b[31m134.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.7/76.7 kB\u001b[0m \u001b[31m234.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 MB\u001b[0m \u001b[31m137.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m161.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m193.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ngensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.16.1 which is incompatible.\nnumba-cuda 0.2.0 requires numba>=0.59.1, but you have numba 0.59.0 which is incompatible.\ndask-cuda 25.2.0 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.59.0 which is incompatible.\ncuml-cu12 25.2.1 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.59.0 which is incompatible.\ncudf-cu12 25.2.2 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.59.0 which is incompatible.\ndistributed-ucxx-cu12 0.42.0 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.59.0 which is incompatible.\ndatasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.5.1 which is incompatible.\nydata-profiling 4.16.1 requires matplotlib<=3.10,>=3.5, but you have matplotlib 3.10.3 which is incompatible.\nydata-profiling 4.16.1 requires scipy<1.16,>=1.4.1, but you have scipy 1.16.1 which is incompatible.\njupyterlab-lsp 3.10.2 requires jupyterlab<4.0.0a0,>=3.1.0, but you have jupyterlab 4.4.3 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\npandas-gbq 0.29.1 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nthinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\ntorchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.7.1 which is incompatible.\nimbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\nlangchain-core 0.3.66 requires packaging<25,>=23.2, but you have packaging 25.0 which is incompatible.\nfastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.1 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"You have to restart the kernel here.","metadata":{"_uuid":"442b8dc8-6bff-48a3-b8fa-1a287ce220a5","_cell_guid":"396ff22e-3082-461a-b784-3735fb76fa03","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"!pip install georeader-spaceml -q\n!pip install netCDF4 spectral -q\n!pip install fsspec gcsfs omegaconf segmentation_models_pytorch hydra-core ipython rasterio  geopandas -q","metadata":{"_uuid":"181720d1-5115-4d1c-a669-39babb50dbab","_cell_guid":"6f5d8592-143b-4cdf-a9cb-cbc565b3344c","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-09-09T08:40:21.078122Z","iopub.execute_input":"2025-09-09T08:40:21.079521Z","iopub.status.idle":"2025-09-09T08:40:39.711922Z","shell.execute_reply.started":"2025-09-09T08:40:21.079471Z","shell.execute_reply":"2025-09-09T08:40:39.710615Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.8/174.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m338.4/338.4 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.0/249.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.8/160.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ncuml-cu12 25.2.1 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.59.0 which is incompatible.\ncudf-cu12 25.2.2 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.59.0 which is incompatible.\ndistributed-ucxx-cu12 0.42.0 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.59.0 which is incompatible.\ngoogle-cloud-automl 1.0.1 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.25.1 which is incompatible.\ndatasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ntorchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.7.1 which is incompatible.\nfastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.1 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import numpy as np\nimport torch\nimport xarray as xr\nfrom utils import EMIT_SCALING_FACTOR, plot_predictions, predict","metadata":{"_uuid":"37335272-ab7c-4a66-ae52-24aed935cbd0","_cell_guid":"74a09f59-bf07-4832-a090-f8be1aa22550","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-09-09T08:40:39.713398Z","iopub.execute_input":"2025-09-09T08:40:39.713731Z","iopub.status.idle":"2025-09-09T08:40:44.644399Z","shell.execute_reply.started":"2025-09-09T08:40:39.713698Z","shell.execute_reply":"2025-09-09T08:40:44.643368Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"from huggingface_hub import hf_hub_download\nfrom georeader.readers import emit, download_utils\nfrom georeader import plot\nimport os\nimport torch\nimport omegaconf\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport georeader","metadata":{"_uuid":"90f77237-148e-4a68-98f2-19837f7f07d8","_cell_guid":"393c51ad-138e-481c-8591-6f05590fb05f","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-09-09T08:40:44.645331Z","iopub.execute_input":"2025-09-09T08:40:44.645913Z","iopub.status.idle":"2025-09-09T08:40:45.500255Z","shell.execute_reply.started":"2025-09-09T08:40:44.645758Z","shell.execute_reply":"2025-09-09T08:40:45.498925Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"file_name = \"EMIT_L1B_RAD_001_20250813T111228_2522507_037.nc\"\ntoken = \"eyJ0eXAiOiJKV1QiLCJvcmlnaW4iOiJFYXJ0aGRhdGEgTG9naW4iLCJzaWciOiJlZGxqd3RwdWJrZXlfb3BzIiwiYWxnIjoiUlMyNTYifQ.eyJ0eXBlIjoiVXNlciIsInVpZCI6Im1haF9zYW0iLCJleHAiOjE3NjA1NzI3OTksImlhdCI6MTc1NTM1NTU0NywiaXNzIjoiaHR0cHM6Ly91cnMuZWFydGhkYXRhLm5hc2EuZ292IiwiaWRlbnRpdHlfcHJvdmlkZXIiOiJlZGxfb3BzIiwiYWNyIjoiZWRsIiwiYXNzdXJhbmNlX2xldmVsIjozfQ.459S_fTfcXafo7Yk017iH4iclfb0z41d57Rj8oTdGYRWCsGD2oGTJGYLrKKHot3JjfgS1kyc33YSAY5JmHy5I0CaYaneDriJIJrBHifka-IJBC3bGow331XgUbiAV_WOM_kJ1ReMSVz7lqr1NiMvf6YGMnE6N9QAQcGCL8UgRZNTYJx8qUrBlpYiPA3p-FQYSbYkINlRjr7myJUkiAHItQ-CTxuAuxbO0j2rdi5Hx1Aldze7NBovlBLjBNnHW6LI9XhaMvlJciXVAXw9T_AuAoD55qkP_ACRIje7hCLz_s-1srjXUGViQfFGy3ixqZuiQ6GYzXRGOU9kJPrjYUWbrA\"\nearthdata_nasa_account = True\n\ndef download_granule(granule_name, token=token, earthdata_nasa_account=earthdata_nasa_account):\n    if earthdata_nasa_account:\n        link = emit.get_radiance_link(granule_name)\n        emit.AUTH_METHOD = \"token\"\n        emit.TOKEN = token # copy your token here\n        headers = {\"Authorization\": f\"Bearer {emit.TOKEN}\"}\n    \n        product = download_utils.download_product(link, headers=headers,  verify=True)\n    \n        rst = emit.EMITImage(product)\n    return rst","metadata":{"_uuid":"415c92b6-d406-4bf1-b315-3786dc58cce7","_cell_guid":"e7f2744e-ba26-421c-9c42-a4acebb252cb","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-09-09T08:40:45.501566Z","iopub.execute_input":"2025-09-09T08:40:45.502810Z","iopub.status.idle":"2025-09-09T08:40:45.510993Z","shell.execute_reply.started":"2025-09-09T08:40:45.502742Z","shell.execute_reply":"2025-09-09T08:40:45.509107Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"import folium\nfrom folium.plugins import HeatMap\nimport numpy as np\nfrom pyproj import Transformer\nimport branca # Folium's parent library\nfrom jinja2 import Template # Used to create the custom element's template\n\n# ==============================================================================\n# This script generates a map where clicking anywhere creates a popup with a\n# link to Google Maps.\n#\n# REQUIRED INPUT VARIABLES:\n# - predgeo: The georeferenced GeoTensor of the prediction heatmap.\n# - final_geo_coordinates: A list of {'lat': ..., 'lon': ...} dicts for each detected source.\n#\n# ==============================================================================\n\n# --- Step 1 & 2: Prepare Data and Transform Coordinates (Same as before) ---\ndef visualize_output(predgeo, final_geo_coordinates=None, heatmap_threshold=0.4):\n    prediction_pixels = predgeo.values\n    rows, cols = np.where(prediction_pixels >= heatmap_threshold)\n    scores = prediction_pixels[rows, cols].astype(float)\n    affine_transform = predgeo.transform\n    source_crs = predgeo.crs\n    target_crs = \"EPSG:4326\"\n    transformer = Transformer.from_crs(source_crs, target_crs, always_xy=True)\n    utm_x, utm_y = affine_transform * (cols + 0.5, rows + 0.5)\n    lons, lats = transformer.transform(utm_x, utm_y)\n    heatmap_data = list(zip(lats, lons, scores))\n    \n    # --- Step 3: Define Map Center and Create the Base Map (Same as before) ---\n    if final_geo_coordinates:\n        map_center = [final_geo_coordinates[0]['lat'], final_geo_coordinates[0]['lon']]\n        points_layer = folium.FeatureGroup(name='Detected Plume Sources', show=True)\n        for i, coords in enumerate(final_geo_coordinates):\n            lat, lon = coords['lat'], coords['lon']\n            popup_html = f\"<b>Candidate #{i+1}</b><br>Lat: {lat:.6f}, Lon: {lon:.6f}<br><a href='https://www.google.com/maps?q={lat},{lon}' target='_blank'>Google Maps</a>\"\n            folium.Marker(\n                location=[lat, lon],\n                popup=folium.Popup(popup_html, max_width=300),\n                icon=folium.Icon(color='cyan', icon='cloud', prefix='fa')\n            ).add_to(points_layer)\n    else:\n        footprint_wgs84 = predgeo.footprint(\"EPSG:4326\")\n        min_lon, min_lat, max_lon, max_lat = footprint_wgs84.bounds\n        map_center = [(min_lat + max_lat) / 2, (min_lon + max_lon) / 2]\n    m_final = folium.Map(location=map_center, zoom_start=14, tiles=\"Esri.WorldImagery\")\n    \n    # --- Step 4: Create and Populate All Layers (Same as before) ---\n    heatmap_layer = folium.plugins.HeatMap(data=heatmap_data, name='Dynamic Methane Heatmap')\n    \n    # --- Step 5: Add \"Click for Popup\" Functionality (THE MODIFIED VERSION) ---\n    \n    # We modify our custom class to create a Leaflet popup instead of opening a new window.\n    class ClickForPopup(branca.element.MacroElement):\n        _template = Template(u\"\"\"\n            {% macro script(this, kwargs) %}\n                function create_popup_on_click(e) {\n                    var lat = e.latlng.lat;\n                    var lon = e.latlng.lng;\n                    var url = `https://www.google.com/maps?q=${lat},${lon}`;\n                    \n                    // Create the HTML content for the popup\n                    var html = `\n                        <b>Location Info</b><br>\n                        Latitude: ${lat.toFixed(6)}<br>\n                        Longitude: ${lon.toFixed(6)}\n                        <hr style=\"margin: 5px 0;\">\n                        <ul>\n                            <li><a href=\"${url}\" target=\"_blank\" rel=\"noopener noreferrer\">View in Google Maps</a></li>\n                        </ul>\n                    `;\n                    \n                    // Create a Leaflet popup object and open it on the map\n                    var popup = L.popup()\n                        .setLatLng(e.latlng)\n                        .setContent(html)\n                        .openOn({{this._parent.get_name()}});\n                }\n                // Attach the function to the map's click event\n                {{this._parent.get_name()}}.on('click', create_popup_on_click);\n            {% endmacro %}\n            \"\"\")\n    \n        def __init__(self):\n            super(ClickForPopup, self).__init__()\n            self._name = 'ClickForPopup'\n    \n    # Create an instance of our custom element and add it to the map.\n    m_final.add_child(ClickForPopup())\n    \n    \n    # --- Step 6: Add Layers to the Map and Save ---\n    heatmap_layer.add_to(m_final)\n    if final_geo_coordinates:\n        points_layer.add_to(m_final)\n    folium.LayerControl().add_to(m_final)\n    output_map_path_final = 'methane_detection_map_popup.html'\n    m_final.save(output_map_path_final)\n    print(f\"Interactive map with popups saved to: {output_map_path_final}\")\n    return m_final\n\n#m_final = visualize_output(predgeo, final_geo_coordinates)\n#m_final","metadata":{"_uuid":"f2fba070-5826-406c-aaf7-a7ff0fc9b85f","_cell_guid":"4ebacb41-6efa-4d85-8917-aa7b259fc783","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-09-09T08:40:45.512280Z","iopub.execute_input":"2025-09-09T08:40:45.512849Z","iopub.status.idle":"2025-09-09T08:40:46.367376Z","shell.execute_reply.started":"2025-09-09T08:40:45.512814Z","shell.execute_reply":"2025-09-09T08:40:46.366312Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"model = torch.load(\"./resources/emit/model.pth\", weights_only=False, map_location=\"cpu\")","metadata":{"_uuid":"572a74f2-30c3-4e44-b83a-a2ca80fa5e46","_cell_guid":"8ee4c06f-affc-47cc-907b-1be3d5afecfe","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-09-09T08:51:06.110976Z","iopub.execute_input":"2025-09-09T08:51:06.111388Z","iopub.status.idle":"2025-09-09T08:51:06.362645Z","shell.execute_reply.started":"2025-09-09T08:51:06.111363Z","shell.execute_reply":"2025-09-09T08:51:06.361888Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"## Run Inference","metadata":{"_uuid":"f5f8ceae-52a3-4753-9c0f-89235a3a3144","_cell_guid":"64f2a347-c8a1-467e-b816-60450e41c1d8","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"granule_names = [\"EMIT_L1B_RAD_001_20250730T075636_2521105_018.nc\",\\\n                \"EMIT_L1B_RAD_001_20250813T111228_2522507_037.nc\",\\\n                \"EMIT_L1B_RAD_001_20250417T095633_2510706_024.nc\",\\\n                \"EMIT_L1B_RAD_001_20250413T113146_2510307_040.nc\",\\\n                \"EMIT_L1B_RAD_001_20241007T051258_2428104_006.nc\",\\\n                \"EMIT_L1B_RAD_001_20241003T064746_2427705_017.nc\"]","metadata":{"_uuid":"6662ec6b-1c81-4763-abad-fa4a94bce448","_cell_guid":"879413df-1770-4d5f-ad78-ffa1b24f0143","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-09-09T08:51:10.457409Z","iopub.execute_input":"2025-09-09T08:51:10.457714Z","iopub.status.idle":"2025-09-09T08:51:10.463180Z","shell.execute_reply.started":"2025-09-09T08:51:10.457696Z","shell.execute_reply":"2025-09-09T08:51:10.461841Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# %% [code] {\"execution\":{\"execution_failed\":\"2025-09-09T05:43:18.326Z\"},\"jupyter\":{\"outputs_hidden\":false}}\nimport torch\nimport torch.nn.functional as F\nimport xarray as xr\nimport georeader\nfrom georeader.readers import emit\nimport gc # Garbage Collector\nimport numpy as np\n\n# Import the necessary tools from rasterio, which you already use elsewhere\nimport rasterio\nfrom rasterio.warp import reproject, Resampling\nfrom rasterio.crs import CRS\n\neuca_preds = {}\nfor file_name in granule_names:\n    print(f\"\\n--- Processing: {file_name} ---\")\n    file_path = f\"../../STARCOP/{file_name}\"\n    \n    with xr.open_dataset(file_path) as ds:\n        radiance = ds[\"radiance\"].load().transpose(\"bands\", \"downtrack\", \"crosstrack\")\n        x = torch.from_numpy(radiance.values * EMIT_SCALING_FACTOR)[None, ...]\n        \n    with torch.no_grad():\n        original_h, original_w = x.shape[-2:]\n        \n        # --- 1. PAD, PREDICT, AND CROP ---\n        output_stride = 32\n        pad_h = (output_stride - original_h % output_stride) % output_stride\n        pad_w = (output_stride - original_w % output_stride) % output_stride\n        padding = (0, pad_w, 0, pad_h)\n        x_padded = F.pad(x, padding, mode='constant', value=0)\n        yhat_padded = predict(model, x_padded)\n        yhat_final = yhat_padded[:, :, :original_h, :original_w]\n\n        # --- [NEW] Print model output statistics ---\n        print(\"\\n--- Model Output Statistics (yhat_final) ---\")\n        # Squeeze the batch dimension to get a tensor of shape [3, H, W]\n        pred_channels = yhat_final.squeeze(0)\n        for i in range(pred_channels.shape[0]):\n            channel_data = pred_channels[i]\n            min_val = torch.min(channel_data).item()\n            max_val = torch.max(channel_data).item()\n            avg_val = torch.mean(channel_data).item()\n            print(f\"  Channel {i}:\")\n            print(f\"    Min: {min_val:.6f}\")\n            print(f\"    Max: {max_val:.6f}\")\n            print(f\"    Avg: {avg_val:.6f}\")\n        print(\"--------------------------------------------\")\n        \n        # --- 2. PREPARE NUMPY ARRAY ---\n        pred_tensor = yhat_final.squeeze(0)[0] \n        pred_numpy = pred_tensor.cpu().numpy()\n\n    # --- 3. REPROJECT THE PREDICTION DATA (THE CORRECTED WORKFLOW) ---\n    \n    # a) Load the original granule to define the SOURCE grid\n    original_granule = emit.EMITImage(file_path)\n    src_transform = original_granule.transform\n    src_crs = CRS.from_user_input(original_granule.crs)\n\n    # b) Create the reprojected granule to define the TARGET grid\n    target_crs_utm_str = georeader.get_utm_epsg(original_granule.footprint(\"EPSG:4326\"))\n    emit_image_utm = original_granule.to_crs(target_crs_utm_str)\n    dst_transform = emit_image_utm.transform\n    dst_crs = CRS.from_user_input(emit_image_utm.crs)\n    \n    # c) Create an empty array with the TARGET dimensions\n    reprojected_pred = np.zeros((emit_image_utm.height, emit_image_utm.width), dtype=pred_numpy.dtype)\n\n    # d) Warp the source data (pred_numpy) into the target array (reprojected_pred)\n    reproject(\n        source=pred_numpy,\n        destination=reprojected_pred,\n        src_transform=src_transform,\n        src_crs=src_crs,\n        dst_transform=dst_transform,\n        dst_crs=dst_crs,\n        resampling=Resampling.bilinear, # Bilinear is a good choice for continuous data\n        dst_nodata=0\n    )\n\n    # --- 4. GEOREFERENCE THE REPROJECTED DATA ---\n    # The dimensions now match perfectly, so this will succeed.\n    predgeo_utm = emit_image_utm.georreference(reprojected_pred, fill_value_default=0)\n\n    print(f\"Successfully created georeferenced map with shape: {predgeo_utm.values.shape}\")\n    \n    visualization = visualize_output(predgeo_utm, heatmap_threshold=0)\n    euca_preds[file_name] = {\n        \"pred\": yhat_final, \n        \"predgeo\": predgeo_utm, \n        \"visualization\": visualization\n    }\n    \n    # Clean up memory before the next loop\n    del original_granule, emit_image_utm, predgeo_utm, pred_numpy, pred_tensor, reprojected_pred\n    gc.collect()\n\nprint(\"\\n--- All granules processed successfully! ---\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"euca_preds[granule_names[0]][\"visualization\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-09T08:54:54.617580Z","iopub.execute_input":"2025-09-09T08:54:54.617887Z","iopub.status.idle":"2025-09-09T08:54:54.632138Z","shell.execute_reply.started":"2025-09-09T08:54:54.617866Z","shell.execute_reply":"2025-09-09T08:54:54.630907Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"<folium.folium.Map at 0x79d4260ad250>","text/html":"<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n    \n    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;\n    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.js&quot;&gt;&lt;/script&gt;\n    &lt;script src=&quot;https://code.jquery.com/jquery-3.7.1.min.js&quot;&gt;&lt;/script&gt;\n    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js&quot;&gt;&lt;/script&gt;\n    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js&quot;&gt;&lt;/script&gt;\n    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.css&quot;/&gt;\n    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css&quot;/&gt;\n    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap-glyphicons.css&quot;/&gt;\n    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css&quot;/&gt;\n    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css&quot;/&gt;\n    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css&quot;/&gt;\n    \n            &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,\n                initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot; /&gt;\n            &lt;style&gt;\n                #map_5630acced5a81da4c5f2de2e31290f18 {\n                    position: relative;\n                    width: 100.0%;\n                    height: 100.0%;\n                    left: 0.0%;\n                    top: 0.0%;\n                }\n                .leaflet-container { font-size: 1rem; }\n            &lt;/style&gt;\n\n            &lt;style&gt;html, body {\n                width: 100%;\n                height: 100%;\n                margin: 0;\n                padding: 0;\n            }\n            &lt;/style&gt;\n\n            &lt;style&gt;#map {\n                position:absolute;\n                top:0;\n                bottom:0;\n                right:0;\n                left:0;\n                }\n            &lt;/style&gt;\n\n            &lt;script&gt;\n                L_NO_TOUCH = false;\n                L_DISABLE_3D = false;\n            &lt;/script&gt;\n\n        \n    &lt;script src=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium@main/folium/templates/leaflet_heat.min.js&quot;&gt;&lt;/script&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    \n    \n            &lt;div class=&quot;folium-map&quot; id=&quot;map_5630acced5a81da4c5f2de2e31290f18&quot; &gt;&lt;/div&gt;\n        \n&lt;/body&gt;\n&lt;script&gt;\n    \n    \n            var map_5630acced5a81da4c5f2de2e31290f18 = L.map(\n                &quot;map_5630acced5a81da4c5f2de2e31290f18&quot;,\n                {\n                    center: [27.196377437311636, 49.63951326901254],\n                    crs: L.CRS.EPSG3857,\n                    ...{\n  &quot;zoom&quot;: 14,\n  &quot;zoomControl&quot;: true,\n  &quot;preferCanvas&quot;: false,\n}\n\n                }\n            );\n\n            \n\n        \n    \n            var tile_layer_412d016e5b240476d9d997ab9a429d42 = L.tileLayer(\n                &quot;https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}&quot;,\n                {\n  &quot;minZoom&quot;: 0,\n  &quot;maxZoom&quot;: 18,\n  &quot;maxNativeZoom&quot;: 18,\n  &quot;noWrap&quot;: false,\n  &quot;attribution&quot;: &quot;Tiles \\u0026copy; Esri \\u0026mdash; Source: Esri, i-cubed, USDA, USGS, AEX, GeoEye, Getmapping, Aerogrid, IGN, IGP, UPR-EGP, and the GIS User Community&quot;,\n  &quot;subdomains&quot;: &quot;abc&quot;,\n  &quot;detectRetina&quot;: false,\n  &quot;tms&quot;: false,\n  &quot;opacity&quot;: 1,\n}\n\n            );\n        \n    \n            tile_layer_412d016e5b240476d9d997ab9a429d42.addTo(map_5630acced5a81da4c5f2de2e31290f18);\n        \n    \n                function create_popup_on_click(e) {\n                    var lat = e.latlng.lat;\n                    var lon = e.latlng.lng;\n                    var url = `https://www.google.com/maps?q=${lat},${lon}`;\n                    \n                    // Create the HTML content for the popup\n                    var html = `\n                        &lt;b&gt;Location Info&lt;/b&gt;&lt;br&gt;\n                        Latitude: ${lat.toFixed(6)}&lt;br&gt;\n                        Longitude: ${lon.toFixed(6)}\n                        &lt;hr style=&quot;margin: 5px 0;&quot;&gt;\n                        &lt;ul&gt;\n                            &lt;li&gt;&lt;a href=&quot;${url}&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;View in Google Maps&lt;/a&gt;&lt;/li&gt;\n                        &lt;/ul&gt;\n                    `;\n                    \n                    // Create a Leaflet popup object and open it on the map\n                    var popup = L.popup()\n                        .setLatLng(e.latlng)\n                        .setContent(html)\n                        .openOn(map_5630acced5a81da4c5f2de2e31290f18);\n                }\n                // Attach the function to the map&#x27;s click event\n                map_5630acced5a81da4c5f2de2e31290f18.on(&#x27;click&#x27;, create_popup_on_click);\n            \n    \n            var heat_map_e1103f25ea3845c1b878133209895c41 = L.heatLayer(\n                [[27.4879049000637, 49.678190923221635, 0.8118534088134766], [27.48791066612116, 49.67879815046501, 0.8118534088134766], [27.487351827019246, 49.67698294215238, 0.830877959728241], [27.48735759823989, 49.67759016606544, 0.9654683470726013], [27.48736336681269, 49.67819739015933, 0.9541025757789612], [27.48680452025405, 49.67638219408314, 0.8426080942153931], [27.486810293989855, 49.676989414846645, 1.0131289958953857], [27.48681606507788, 49.677596635791055, 1.0283534526824951], [27.486821833518118, 49.678203856916284, 1.0316836833953857], [27.486262987313786, 49.67638866956507, 0.9273530840873718], [27.48626876091691, 49.67699588736001, 1.0131289958953857], [27.486274531872315, 49.67760310533584, 1.0236319303512573], [27.486280300180002, 49.67821032349249, 1.0316836833953857], [27.486286065839955, 49.678817541829886, 0.890291690826416], [27.48572722780042, 49.67700235969247, 0.9111309051513672], [27.485732998623206, 49.677609574699815, 0.9111309051513672], [27.48573876679833, 49.678216789887976, 0.8746722340583801], [27.12056513609511, 49.503371703997516, 0.971550703048706], [27.12057158453256, 49.50397688979231, 0.828484296798706], [27.120017164316526, 49.50277372923122, 1.42033851146698], [27.120023615210435, 49.50337891191161, 0.971550703048706], [27.120030063498344, 49.503984094794426, 1.3845618963241577], [27.120036509180252, 49.50458927787957, 1.3845618963241577], [27.119469190187687, 49.50217576028881, 1.1831165552139282], [27.11947564353793, 49.5027809398548, 1.1831165552139282], [27.119482094282233, 49.503386119623286, 2.1475226879119873], [27.119488542420598, 49.50399129959419, 2.1475226879119873], [27.11949498795302, 49.504596479767436, 1.629014015197754], [27.119501430879502, 49.50520166014293, 1.629014015197754], [27.118934122715793, 49.50278815027587, 1.7225087881088257], [27.118940573310493, 49.50339332713255, 2.565392255783081], [27.118947021299313, 49.50399850419163, 2.689875841140747], [27.118953466682257, 49.50460368145305, 2.2547500133514404], [27.118959909459317, 49.5052088589167, 2.3005809783935547], [27.118966349630487, 49.505814036582535, 1.3017723560333252], [27.118392601850122, 49.50279536049446, 1.3347928524017334], [27.118399052295217, 49.50340053443939, 2.127309560775757], [27.1184055001345, 49.50400570858673, 2.689875841140747], [27.118411945367956, 49.504610882936404, 2.8024191856384277], [27.118418387995597, 49.50521605748832, 2.1483707427978516], [27.118424828017403, 49.50582123224239, 2.1483707427978516], [27.118431265433387, 49.50642640719855, 0.8821973204612732], [27.118437700243533, 49.50703158235671, 0.8821973204612732], [27.117857531236417, 49.50340774154383, 1.5172927379608154], [27.117863978926152, 49.504012912779515, 2.227781057357788], [27.117870424010132, 49.50461808421752, 2.135174512863159], [27.117876866488356, 49.50522325585777, 2.669759750366211], [27.117883306360806, 49.50582842770017, 1.7263271808624268], [27.117889743627487, 49.50643359974465, 1.7263271808624268], [27.11731601013408, 49.503414948445865, 1.63340163230896], [27.117322457674284, 49.50402011676997, 1.4806619882583618], [27.117328902608786, 49.5046252852964, 2.135174512863159], [27.117335344937587, 49.50523045402506, 1.6914277076721191], [27.11734178466068, 49.50583562295588, 2.1199779510498047], [27.117348221778062, 49.50644079208876, 1.2476428747177124], [27.116780936378873, 49.504027320558116, 1.4806619882583618], [27.116787381163903, 49.50463248617304, 1.04109787940979], [27.11679382334328, 49.50523765199019, 1.04109787940979], [27.116800262917018, 49.5058428180095, 0.9843825697898865], [27.01501629905285, 49.671674878417654, 0.9238808155059814], [27.015022001813545, 49.672279541759906, 0.9238808155059814], [27.015027701979278, 49.67288420528121, 0.8585536479949951], [27.01503339955005, 49.67348886898146, 0.8585536479949951], [27.01446331761039, 49.670471926578536, 0.8257582783699036], [27.014469025428262, 49.67107658666555, 1.392846703529358], [27.014474730651244, 49.67168124693177, 1.3302220106124878], [27.014480433279317, 49.672285907377095, 1.6942229270935059], [27.01448613331249, 49.67289056800147, 1.783180832862854], [27.01449183075076, 49.6734952288048, 1.783180832862854], [27.014497525594123, 49.674099889787, 1.4378633499145508], [27.013916039151177, 49.669873643696285, 0.8230564594268799], [27.01392174943115, 49.67047830070719, 1.253121018409729], [27.013927457116285, 49.67108295789737, 1.392846703529358], [27.01393316220658, 49.67168761526675, 1.5667386054992676], [27.013938864702045, 49.67229227281525, 1.6942229270935059], [27.013944564602653, 49.67289693054278, 1.9302583932876587], [27.013950261908423, 49.67350158844926, 2.026860237121582], [27.01395595661935, 49.67410624653463, 2.026860237121582], [27.01396164873542, 49.67471090479877, 1.4176229238510132], [27.0133744710617, 49.669880020542394, 0.9271395802497864], [27.013380181208866, 49.67048467465656, 0.9271395802497864], [27.013385888761263, 49.67108932894999, 1.3746761083602905], [27.01339159371888, 49.67169398342262, 1.3746761083602905], [27.013397296081727, 49.67229863807436, 1.8709135055541992], [27.01340299584978, 49.67290329290513, 2.257402181625366], [27.013408693023056, 49.67350794791486, 2.257402181625366], [27.013414387601536, 49.67411260310345, 2.257425308227539], [27.013420079585234, 49.674717258470835, 2.257425308227539], [27.01283861294353, 49.67049104842665, 1.1280393600463867], [27.01284432036319, 49.67109569982342, 1.1280393600463867], [27.01285002518813, 49.67170035139938, 1.710471272468567], [27.012855727418355, 49.67230500315444, 2.091989517211914], [27.012861427053856, 49.67290965508854, 2.295189619064331], [27.012867124094633, 49.673514307201586, 2.78300404548645], [27.012872818540686, 49.67411895949349, 2.702031135559082], [27.012878510392003, 49.67472361196418, 2.704782485961914], [27.01288419964859, 49.675328264613576, 0.9696964025497437], [27.012308456614328, 49.671706719197026, 1.5922062397003174], [27.012314158711938, 49.6723113680555, 2.091989517211914], [27.01231985821489, 49.672916017093, 2.4394803047180176], [27.01232555512317, 49.67352066630944, 2.929086208343506], [27.012331249436787, 49.67412531570475, 2.929086208343506], [27.01177258996248, 49.67231773277753, 1.7364625930786133], [27.01177828933288, 49.67292237891852, 1.6818567514419556], [27.011783986108664, 49.67352702523844, 2.518914222717285], [27.01178968028985, 49.67413167173723, 1.8290022611618042], [27.011236720407823, 49.6729287405651, 1.6818567514419556], [27.011242417051122, 49.673533383988584, 0.9418714046478271], [27.01124811109987, 49.67413802759093, 1.8290022611618042], [26.960219437174004, 49.84579529773612, 1.0221993923187256], [26.960224383080487, 49.84639970817375, 0.818821370601654], [26.960229326397503, 49.84700411876671, 1.4106667041778564], [26.960234267125042, 49.847608529514915, 1.1307852268218994], [26.96023920526311, 49.84821294041828, 1.319028377532959], [26.960244140811696, 49.848817351476725, 0.8206157088279724], [26.95967288036694, 49.84519641111731, 1.0782939195632935], [26.959677828747637, 49.84580081851009, 1.0221993923187256], [26.95968277453893, 49.84640522605827, 1.5206117630004883], [26.95968771774082, 49.847009633761786, 1.5206117630004883], [26.959692658353294, 49.84761404162054, 1.5127984285354614], [26.95969759637635, 49.84821844963445, 1.1278542280197144], [26.959126321158376, 49.84459753027729, 0.9785404205322266], [26.959131272013174, 49.84520193462523, 0.9785404205322266], [26.959136220278623, 49.84580633912865, 1.5034124851226807], [26.95914116595473, 49.84641074378748, 1.543723225593567], [26.959146109041487, 49.84701514860162, 1.5767983198165894], [26.959151049538896, 49.847619553571, 1.3097724914550781], [26.959155987446948, 49.848223958695556, 1.2551437616348267], [26.958589663616756, 49.84520745797767, 1.138627052307129], [26.958594611766962, 49.84581185959181, 1.3714629411697388], [26.958599557327883, 49.84641626136136, 1.4182261228561401], [26.95860450029951, 49.84702066328622, 1.2842156887054443], [26.958609440681858, 49.847625065366316, 1.3097724914550781], [26.958614378474895, 49.84822946760156, 0.828853964805603], [26.9580431045535, 49.844608582605154, 0.875432014465332], [26.95804805517768, 49.845212981174626, 1.138627052307129], [26.95805300321264, 49.84581737989958, 1.1953943967819214], [26.958057948658368, 49.84642177877992, 1.1515625715255737], [26.958062891514878, 49.84702617781558, 1.1515625715255737], [26.957506446695955, 49.845218504216106, 0.946574330329895], [26.95751139461567, 49.84582290005194, 0.9341892600059509], [26.95751633994622, 49.846427296043174, 0.9341892600059509], [26.956959887778005, 49.84461963431079, 0.8296517729759216], [26.956408371002624, 49.84341638059224, 0.9987457990646362], [26.95641332645897, 49.84402077018344, 0.9987457990646362], [26.955866762739035, 49.84342191183391, 1.0341166257858276], [26.95587171807996, 49.84402629853625, 0.9257618188858032], [26.955876670831906, 49.844630685394215, 0.9257618188858032], [26.955320196618374, 49.84282305926201, 0.9330338835716248], [26.955325154432792, 49.84342744291987, 0.9551473259925842], [26.955330109658295, 49.84403182673343, 1.0196796655654907], [26.95478354608389, 49.84343297385012, 0.9551473259925842]],\n                {\n  &quot;minOpacity&quot;: 0.5,\n  &quot;maxZoom&quot;: 18,\n  &quot;radius&quot;: 25,\n  &quot;blur&quot;: 15,\n}\n            );\n        \n    \n            heat_map_e1103f25ea3845c1b878133209895c41.addTo(map_5630acced5a81da4c5f2de2e31290f18);\n        \n    \n            var layer_control_44d644301b1bfe3e4101e6116005051a_layers = {\n                base_layers : {\n                    &quot;esriworldimagery&quot; : tile_layer_412d016e5b240476d9d997ab9a429d42,\n                },\n                overlays :  {\n                    &quot;Dynamic Methane Heatmap&quot; : heat_map_e1103f25ea3845c1b878133209895c41,\n                },\n            };\n            let layer_control_44d644301b1bfe3e4101e6116005051a = L.control.layers(\n                layer_control_44d644301b1bfe3e4101e6116005051a_layers.base_layers,\n                layer_control_44d644301b1bfe3e4101e6116005051a_layers.overlays,\n                {\n  &quot;position&quot;: &quot;topright&quot;,\n  &quot;collapsed&quot;: true,\n  &quot;autoZIndex&quot;: true,\n}\n            ).addTo(map_5630acced5a81da4c5f2de2e31290f18);\n\n        \n    \n            tile_layer_412d016e5b240476d9d997ab9a429d42.addTo(map_5630acced5a81da4c5f2de2e31290f18);\n        \n    \n            heat_map_e1103f25ea3845c1b878133209895c41.addTo(map_5630acced5a81da4c5f2de2e31290f18);\n        \n&lt;/script&gt;\n&lt;/html&gt;\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"euca_preds = {}\nfor file_name in granule_names:\n    print(f\"Processing granule: {file_name}\")\n\n    # Step 1: Load radiance data from the NetCDF file\n    # Use os.path.join to ensure correct path construction\n    granule_path = os.path.join(\"../../STARCOP/\", file_name)\n    with xr.open_dataset(granule_path) as ds:\n        radiance = ds[\"radiance\"].load().transpose(\"bands\", \"downtrack\", \"crosstrack\")\n        x = torch.from_numpy(radiance.values * EMIT_SCALING_FACTOR)[None, ...]\n    \n    # Get original dimensions for cropping\n    original_h, original_w = x.shape[-2:]\n    \n    # Step 2: Pad the input tensor for model compatibility\n    output_stride = 32\n    pad_h = (output_stride - original_h % output_stride) % output_stride\n    pad_w = (output_stride - original_w % output_stride) % output_stride\n    padding_tuple = (0, pad_w, 0, pad_h) # (pad_left, pad_right, pad_top, pad_bottom)\n    x_padded = F.pad(x, padding_tuple, mode='constant', value=0)\n    \n    # Step 3: Run inference\n    with torch.no_grad(): # Disable gradient calculations to save memory\n        yhat_padded = predict(model, x_padded)\n    \n    # Step 4: Crop the output to original dimensions\n    # Ensure yhat_final is on CPU and converted to NumPy for georeferencing\n    yhat_final_cpu_np = yhat_padded[:, :original_h, :original_w].cpu().numpy()\n    \n    # Step 5: Download/Load the EMIT granule for georeferencing\n    # Pass the full path to download_granule if it expects it, or just the name\n    # depending on how your download_granule is implemented.\n    # Assuming it expects the full path to check for local existence.\n    granule_obj = download_granule(granule_name=file_name) # Assuming download_granule handles path correctly\n\n    # Step 6: Reproject the EMIT granule to UTM\n    crs_utm = georeader.get_utm_epsg(granule_obj.footprint(\"EPSG:4326\"))\n    emit_image_utm = granule_obj.to_crs(crs_utm)\n\n    # Step 7: Georeference the model prediction\n    # Use the first channel (index 0) of the prediction for the heatmap\n    predgeo = emit_image_utm.georreference(yhat_final_cpu_np[0], fill_value_default=0)\n    \n    # Step 8: (Optional) Find maxima and generate visualization\n    # If you need maxima, you must call get_maxima here.\n    # For now, I'm adapting based on your commented out line and the visualize_output signature.\n    # If get_maxima is not called, final_geo_coordinates would be undefined.\n    # Let's assume for now visualize_output can work without final_geo_coordinates\n    # or you'll re-enable get_maxima.\n    \n    # If you want to use get_maxima, uncomment and ensure it's defined in this scope:\n    # final_maxima_coords, final_geo_coordinates = get_maxima(predgeo.values) # get_maxima expects a numpy array\n    # visualization = visualize_output(predgeo, final_geo_coordinates)\n    \n    # If not using get_maxima for Eucalyptus, call visualize_output without it\n    visualization = visualize_output(predgeo) \n    \n    # Store results\n    euca_preds[file_name] = {\n        \"pred\": yhat_final_cpu_np, # Store the numpy array\n        \"predgeo\": predgeo,\n        # \"maxima\": final_maxima_coords, # Uncomment if using get_maxima\n        # \"geomaxima\": final_geo_coordinates, # Uncomment if using get_maxima\n        \"visualization\": visualization\n    }\n    \n    # Explicitly delete large objects no longer needed to free memory\n    del x, x_padded, yhat_padded, yhat_final_cpu_np\n    del granule_obj, emit_image_utm, predgeo\n    \n    # Force Python's garbage collector to run\n    gc.collect()\n    \n    # If using CUDA, clear the GPU cache\n    if torch.cuda.is_available():\n        torch.cuda.empty_cache()\n\nprint(\"\\nAll granules processed for Project-Eucalyptus.\")","metadata":{"_uuid":"47bba01a-af70-4952-bd2d-30855f8c984a","_cell_guid":"bbeb6a46-7106-436c-9f76-53135e8b5cc9","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-09-09T08:54:54.633124Z","iopub.execute_input":"2025-09-09T08:54:54.633453Z","iopub.status.idle":"2025-09-09T08:54:58.110695Z","shell.execute_reply.started":"2025-09-09T08:54:54.633435Z","shell.execute_reply":"2025-09-09T08:54:58.109245Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"Processing granule: EMIT_L1B_RAD_001_20250730T075636_2521105_018.nc\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/1968700082.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgranule_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mradiance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"radiance\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bands\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"downtrack\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"crosstrack\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mradiance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mEMIT_SCALING_FACTOR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Get original dimensions for cropping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xarray/core/dataarray.py\u001b[0m in \u001b[0;36mvalues\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 784\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    785\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m         \"\"\"\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":21},{"cell_type":"code","source":"subplot_props = {\n    \"likelihood\": {\n        \"title\": \"Likelihood score\",\n        \"imshow_kwargs\": {\"cmap\": \"Greys\", \"vmin\": 0, \"vmax\": 1},\n    },\n    \"conditional\": {\n        \"title\": \"Conditional prediction ({units})\",\n        \"imshow_kwargs\": {\"cmap\": \"Reds\", \"vmin\": 0},\n    },\n    \"marginal\": {\n        \"title\": \"Marginal prediction ({units})\",\n        \"imshow_kwargs\": {\"cmap\": \"Reds\", \"vmin\": 0},\n    },\n}\n\nplot_predictions(\n    yhat_gamma_concentration, subplot_props, units=r\"$\\gamma \\cdot mol/m^2$\"\n)","metadata":{"_uuid":"b31c0851-1d75-4979-b1fa-c5213ef27f01","_cell_guid":"74ded7f5-6d22-42c7-a4fa-a1058bdadf85","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-09-09T08:54:58.111512Z","iopub.status.idle":"2025-09-09T08:54:58.111805Z","shell.execute_reply.started":"2025-09-09T08:54:58.111665Z","shell.execute_reply":"2025-09-09T08:54:58.111677Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pred2geo = emit_image_utm.georreference(yhat_final[0], fill_value_default=0)\ntransform = pred2geo.transform\n#utm_x, utm_y = transform * (max_col + 0.5, max_row + 0.5)\nsource_crs = pred2geo.crs","metadata":{"_uuid":"c75769cc-b2ad-402a-b38e-b76521413e4e","_cell_guid":"78c94264-58c8-4670-95a5-6ecbfc0af5f3","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-09-09T08:54:58.113857Z","iopub.status.idle":"2025-09-09T08:54:58.114361Z","shell.execute_reply.started":"2025-09-09T08:54:58.114130Z","shell.execute_reply":"2025-09-09T08:54:58.114153Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"visualize_output(pred2geo)","metadata":{"_uuid":"ac63b150-0c44-434c-9d22-df8991745964","_cell_guid":"d37454d1-fda6-491d-ab35-e9ea6434c01a","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-09-09T08:54:58.115582Z","iopub.status.idle":"2025-09-09T08:54:58.116026Z","shell.execute_reply.started":"2025-09-09T08:54:58.115807Z","shell.execute_reply":"2025-09-09T08:54:58.115827Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Ensembling","metadata":{"_uuid":"f87b6646-9c28-433e-a822-a7e5ac823ca3","_cell_guid":"bc7378d8-1e9b-4956-b91d-79a17305d7d7","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# %% [markdown]\n# # Ensembling STARCOP and Project-Eucalyptus\n# \n# To create a more robust prediction, we can ensemble the outputs of the two models. The most direct approach is to combine their respective likelihood scores. We will perform a weighted average of the STARCOP confidence map and the Project-Eucalyptus `likelihood` map.\n\n# %% [code]\nimport numpy as np\nimport gc\n\n# --- Configuration for Ensembling ---\n# You can adjust these weights. They must sum to 1.0.\n# A 50/50 split is a good starting point.\nWEIGHT_STARCOP = 0.5\nWEIGHT_EUCALYPTUS = 0.5\n\nassert WEIGHT_STARCOP + WEIGHT_EUCALYPTUS == 1.0, \"Weights must sum to 1.0\"\n\n# This dictionary will store the final ensembled results for each granule\nensembled_results = {}\n\nprint(\"--- Starting Model Ensembling ---\")\n\nfor granule_name in granule_names:\n    print(f\"\\nProcessing granule: {granule_name}\")\n\n    # --- 1. Retrieve the prediction objects for this granule ---\n    starcop_predgeo = granules[granule_name][\"predgeo\"]\n    euca_likelihood_geo = euca_preds[granule_name][\"likelihood\"][\"predgeo\"]\n\n    # --- 2. Perform Sanity Checks ---\n    # Ensure the georeferenced objects are on the same grid before combining them.\n    # This is crucial for accurate pixel-wise operations.\n    print(\"  - Performing sanity checks...\")\n    assert starcop_predgeo.values.shape == euca_likelihood_geo.values.shape, \\\n        f\"Shape mismatch: STARCOP is {starcop_predgeo.values.shape}, Eucalyptus is {euca_likelihood_geo.values.shape}\"\n    assert starcop_predgeo.crs == euca_likelihood_geo.crs, \"CRS mismatch\"\n    # Note: A direct transform comparison can sometimes fail due to float precision.\n    # We rely on the shape and CRS checks which are sufficient given our pipeline.\n    print(\"  - Sanity checks passed. Grids are aligned.\")\n\n    # --- 3. Perform the Weighted Average ---\n    print(\"  - Calculating weighted average...\")\n    starcop_array = starcop_predgeo.values\n    euca_array = euca_likelihood_geo.values\n\n    # The core ensembling calculation\n    ensembled_array = (WEIGHT_STARCOP * starcop_array) + (WEIGHT_EUCALYPTUS * euca_array)\n    \n    # --- 4. Create a new GeoTensor for the ensembled result ---\n    # We can reuse the georeferencing info from one of the inputs since they are aligned.\n    GeoObjectType = type(starcop_predgeo)\n    ensembled_geo = GeoObjectType(\n        values=ensembled_array,\n        transform=starcop_predgeo.transform,\n        crs=starcop_predgeo.crs\n    )\n    print(\"  - Created new ensembled GeoTensor.\")\n\n    # --- 5. Visualize and Store the Result ---\n    visualization = visualize_output(ensembled_geo)\n    \n    ensembled_results[granule_name] = {\n        \"predgeo\": ensembled_geo,\n        \"visualization\": visualization\n    }\n    \n    # Clean up memory\n    del starcop_predgeo, euca_likelihood_geo, ensembled_geo\n    gc.collect()\n\nprint(\"\\n--- All granules have been ensembled successfully! ---\")\n\n# %% [markdown]\n# You can now display the ensembled map for any granule. For example, for the first one:\n\n# %% [code]\n# Display the visualization for the first granule in the list\nensembled_results[granule_names[0]][\"visualization\"]","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}